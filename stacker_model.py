from tpot import TPOTClassifier
from tpot import TPOTClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from sklearn.decomposition import FastICA
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures
from tpot.export_utils import set_param_recursive
import xgboost as xgb
import csv

def read_csv_file(file_path: str) -> np.array:
    """Reads the labels from the csv file and returns it as an array

    :param file_path: path to the csv file containing the labels to the files in the dataset
    :return: labels as a numpy array
    """
    with open(file_path, 'r') as f:
        f.readline()
        vals = f.readlines()

    data= dict()
    # data = np.empty(shape=(len(vals), 1), dtype=np.float32)

    for val in vals:
        val = val.rstrip('\n')
        val_split = val.split(",")
        data[int(val_split[0])] = int(val_split[1])

    return data

def read_train_file(file_path: str) -> np.array:
    """Reads the labels from the csv file and returns it as an array
    :param file_path: path to the csv file containing the labels to the files in the dataset
    :return: labels as a numpy array
    """
    with open(file_path, 'r') as f:
        f.readline()
        vals = f.readlines()
    data= dict()
    # data = np.empty(shape=(len(vals), 1), dtype=np.float32)
    for val in vals:
        val = val.rstrip('\n')
        val_split = val.split(",")
        data[int(val_split[0])] = float(val_split[1])
    return data

LABELS_FILE = 'valid_y.csv'
DATA_FILE = 'new.csv'
labels = read_csv_file(LABELS_FILE)
train_data = read_train_file(DATA_FILE)
labels_df = pd.DataFrame(list(labels.items()), columns=['Idx', 'y'])
train_df = pd.DataFrame(list(train_data.items()), columns=['Idx', 'X'])
result = train_df.merge(labels_df, how='inner')
result = result.drop('Idx', axis=1)
X = result['X'].to_frame().to_numpy()
y = result['y'].to_frame().to_numpy().ravel()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)


# Average CV score on the training set was: 0.969623196016526
exported_pipeline = make_pipeline(
    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),
    FastICA(tol=0.0),
    GradientBoostingClassifier(learning_rate=0.01, max_depth=10, max_features=0.7000000000000001, min_samples_leaf=11, min_samples_split=11, n_estimators=100, subsample=0.3)
)
# Fix random state for all the steps in exported pipeline
set_param_recursive(exported_pipeline.steps, 'random_state', 42)

exported_pipeline.fit(X_train, y_train)
results = exported_pipeline.predict(testing_features)

print("acc on VALID:", accuracy_score(exported_pipeline.predict(X_test), y_test))

DATA_FILE2 = 'epochs2.csv'
pred_data = read_train_file(DATA_FILE2)

for idx, prob in pred_data:
    predicted[idx] = exported_pipeline.predict(prob)

with open('output.csv', 'w') as csv_file:
    writer = csv.writer(csv_file)
    for key, value in predicted.items():
       writer.writerow([key, value])